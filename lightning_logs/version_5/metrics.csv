epoch,step,train_loss,val_loss,val_mae,val_rmse
0,308,,543.6860961914062,18.303415298461914,20.713287353515625
0,308,1851.7518310546875,,,
1,617,,96.91504669189453,6.962528705596924,8.817831039428711
1,617,515.2046508789062,,,
2,926,,50.859901428222656,4.882111549377441,6.398849010467529
2,926,131.32650756835938,,,
3,1235,,47.50806427001953,4.740296840667725,6.22078275680542
3,1235,109.63590240478516,,,
4,1544,,41.38014602661133,4.38295841217041,5.832894802093506
4,1544,104.89390563964844,,,
5,1853,,43.47123718261719,4.760776042938232,6.09678316116333
5,1853,99.88446044921875,,,
6,2162,,44.10960006713867,4.512320041656494,5.982852458953857
6,2162,102.12672424316406,,,
7,2471,,42.34039306640625,4.622072696685791,6.019357204437256
7,2471,97.27106475830078,,,
8,2780,,38.914772033691406,4.382725238800049,5.72397518157959
8,2780,95.08963775634766,,,
9,3089,,34.1162109375,3.97147536277771,5.284993648529053
9,3089,94.12159729003906,,,
10,3398,,39.773231506347656,4.317449569702148,5.681313514709473
10,3398,93.94194030761719,,,
11,3707,,36.413063049316406,4.025297164916992,5.418658256530762
11,3707,95.74970245361328,,,
